{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Test Cristian Magallanes: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In this exercise I will prepare and  aggregate the three types of data and calculate fields needed to join and tag according to agency code and destination code. For this case I'll prioricize First\\-contact attribution of campaings and measure the times adn days these iterations take\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports \n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define Gobal files parameters for read CSV\n",
    "\n",
    "delimiter = ';'\n",
    "\n",
    "encoding = 'latin-1'\n",
    "\n",
    "file_path = 'data/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Dictionary of destinations\n",
    "\n",
    "dic_destinations = { 'varadero':'VAR', 'rivera maya':'RIV' ,  'punta cana':'PUN',  'AlbÃ¢nia':'ALB', 'menorca':'MEN',  'tenerife':'TFS',  'Maiorca':'PMI', 'gran canaria':'LPA', 'lanzarote': 'ACE',  'mallorca':'PMI'\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define Bookings file atributes\n",
    "\n",
    "# Define the file name\n",
    "booking_file_name = 'TRADING_BOOKINGS.csv'\n",
    "\n",
    "parse_dates = ['DAY_BW']\n",
    "\n",
    "# Define the data types for each column\n",
    "website_data_types = {'BOOKING_ID':str, 'BRAND':str, 'DAY_BW':str, 'DESTINATION_CODE':str, 'SUBPRODUCT_TYPE':str, 'DAY_TP':str, 'DAY_TP_END':str, 'TRAVEL_ORIGIN':str, 'DESTINATION_MARKET':str, 'PAXES':str, 'ADULTS':str, 'CHILDS':str, 'INFANTS':str, 'DAY_RETURN_FLIGHT':str, 'AGENCY_CODE':str, 'PVD':float, 'TTV':float, 'SALES_CHANNEL':str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "df_Bookings = pd.read_csv(file_path+booking_file_name ,  header='infer',  thousands='.',  decimal=',',  dtype=website_data_types, parse_dates=parse_dates, delimiter=delimiter, encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert date fromat\n",
    "df_Bookings['DAY_BW'] = pd.to_datetime(df_Bookings['DAY_BW'], format= \"%d/%m/%Y %H:%M\" )\n",
    "\n",
    "# rename columns\n",
    "df_Bookings.rename(columns={'BOOKING_ID': 'booking_id','DAY_BW': 'booking_time', 'TRAVEL_ORIGIN' : 'from', 'DESTINATION_CODE' : 'destination_code', 'BRAND': 'brand', 'SALES_CHANNEL': 'channel',  'AGENCY_CODE': 'agency_code', 'SUBPRODUCT_TYPE': 'subproduct',  'TTV': 'ttv'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Group data\n",
    "\n",
    "df_Bookings = df_Bookings.groupby(['booking_id', 'booking_time',  'from', 'destination_code', 'agency_code', 'brand', 'channel']).agg(    ttv= ('ttv' , 'sum')\n",
    "                                                                   ).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define Website file atributes\n",
    "\n",
    "# Define the file name\n",
    "website_file_name = 'WEBSITE_TRACKING.csv'\n",
    "\n",
    "# Define the data types for each column\n",
    "website_data_types = {'WEB_USER':str, 'EMAIL':str, 'TIME':int, 'CHARSET':str, 'LANGUAGE':str, 'SCREEN':str, 'VIEWPORT':str, 'TITTLE': str, 'DESCRIPTION': str, 'URL': str, 'DESTINATION_CODE':str, 'USER_AGENT':str, 'BROWSER':str, 'OS':str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "df_Website = pd.read_csv(file_path+website_file_name ,  header='infer',  thousands='.',  dtype=website_data_types, delimiter=delimiter, encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert date fromat\n",
    "df_Website['TIME'] = pd.to_datetime(df_Website['TIME'], unit='s')\n",
    "\n",
    "\n",
    "# rename columns\n",
    "df_Website.rename(columns={'EMAIL': 'email', 'TIME': 'time', 'TITTLE' : 'title', 'DESTINATION_CODE': 'destination_code'}, inplace=True)\n",
    "\n",
    "# delete records without email \n",
    "df_Website = df_Website.dropna(subset=['email'])\n",
    "\n",
    "# trim spaces\n",
    "df_Website['email'] = df_Website['email'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Group data\n",
    "\n",
    "df_Website = df_Website.groupby(['email', 'title', 'destination_code']).agg(    time= ('time' , 'min'),\n",
    "                                                                                reach_website= ('email', 'size')\n",
    "                                                                            ).reset_index()\n",
    "df_Website['reach_website'] =df_Website['reach_website'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define Email file atributes\n",
    "\n",
    "# Define the file name\n",
    "email_file_name = 'EMAIL_TRACKING.csv'\n",
    "\n",
    "# Define the data types for each column\n",
    "email_data_types = {'agency_code':str,'email':str, 'time':int, 'email_subject':str,'event_name':str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "df_Email = pd.read_csv(file_path+email_file_name ,  header='infer',  dtype=email_data_types, delimiter=delimiter, encoding=encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert date format\n",
    "df_Email['time'] = pd.to_datetime(df_Email['time'], unit='s')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Group data\n",
    "\n",
    "df_Email['dropped'] = np.where(df_Email['event_name'] == 'email_dropped', 1, 0)\n",
    "df_Email['delivered'] = np.where(df_Email['event_name'] == 'email_delivered', 1, 0)\n",
    "df_Email['Open'] = np.where(df_Email['event_name'] == 'email_open', 1, 0)\n",
    "df_Email['blocked'] = np.where(df_Email['event_name'] == 'email_blocked', 1, 0)\n",
    "df_Email['click'] = np.where(df_Email['event_name'] == 'email_click', 1, 0)\n",
    "df_Email['bounce'] = np.where(df_Email['event_name'] == 'email_bounce', 1, 0)\n",
    "df_Email['unsubscribe'] = np.where(df_Email['event_name'] == 'email_unsubscribe', 1, 0)\n",
    "df_Email['reach_email'] = np.where((df_Email['Open'] > 0) | (df_Email['click'] > 0), 1, 0)\n",
    "df_Email = df_Email.groupby(['agency_code','email', 'email_subject' ]).agg({    'time': 'min',\n",
    "                                                                                'delivered': 'sum', \n",
    "                                                                                'dropped': 'sum',\n",
    "                                                                                'Open': 'sum', \n",
    "                                                                                'blocked': 'sum', \n",
    "                                                                                'click': 'sum', \n",
    "                                                                                'bounce': 'sum', \n",
    "                                                                                'unsubscribe': 'sum',\n",
    "                                                                                'reach_email':'sum'\n",
    "                                                                            }).reset_index()\n",
    "\n",
    "# convert to integers\n",
    "\n",
    "df_Email['delivered'] =df_Email['delivered'].astype(int) \n",
    "df_Email['dropped'] =df_Email['dropped'].astype(int) \n",
    "df_Email['Open'] =df_Email['Open'].astype(int) \n",
    "df_Email['blocked'] =df_Email['blocked'].astype(int) \n",
    "df_Email['click'] =df_Email['click'].astype(int) \n",
    "df_Email['bounce'] =df_Email['bounce'].astype(int) \n",
    "df_Email['unsubscribe'] =df_Email['unsubscribe'].astype(int) \n",
    "df_Email['reach_email'] =df_Email['reach_email'].astype(int) \n",
    "df_Email['email'] = df_Email['email'].str.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " # create agency code column on Website\n",
    "\n",
    "df_Website['agency_code'] = df_Website['email'].map(df_Email.set_index('email')['agency_code'].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Match destinations on Email\n",
    "\n",
    "# switch dictionary\n",
    "def look_destinations(x):\n",
    "    for key, value in dic_destinations.items():\n",
    "        if key in x:\n",
    "            return value \n",
    "    return None  \n",
    "\n",
    "\n",
    "df_Email['destination_code'] = df_Email['email_subject'].str.lower().apply(look_destinations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sample of data\n",
    "df_Email.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sample of data\n",
    "df_Website.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sample of data\n",
    "df_Bookings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image(\"images/agregate.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregate model with 3 enities where we can analyze campaings eficiency and client journey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# union both Web and email activity\n",
    "df_client_journey = [df_Website, df_Email]\n",
    "df_client_journey = pd.concat(df_client_journey)\n",
    "\n",
    "\n",
    "# calculate total  reach adding emails open and click and websites opened\n",
    "\n",
    "df_client_journey['reach'] = df_client_journey['reach_website'].fillna(0) + df_client_journey['reach_email'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Group data jorney\n",
    "\n",
    "df_client_journey = df_client_journey.groupby(['agency_code', 'destination_code']).agg( {  \n",
    "                                                                                'time': 'min',\n",
    "                                                                                'reach':'sum'\n",
    "                                                                            }\n",
    "                                                                            ).reset_index()\n",
    "\n",
    "\n",
    "df_client_journey['reach'] =df_client_journey['reach'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Join activity with bookings\n",
    "\n",
    "df_client_journey = pd.merge(df_client_journey, df_Bookings, on=['agency_code', 'destination_code'], how='left')\n",
    "\n",
    "df_client_journey = df_client_journey[['agency_code', 'destination_code', 'time', 'booking_time', 'brand', 'channel','from', 'reach', 'ttv']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add meetric succesfull booking metrics where book was made after first atempt and ttv is not null\n",
    "\n",
    "\n",
    "df_client_journey_book= df_client_journey.query ('time < booking_time and  ttv >= 0 and reach>0' ).copy()\n",
    "\n",
    "df_client_journey['book'] = False\n",
    "\n",
    "# add succesfull booking tag \n",
    "\n",
    "df_client_journey_book['book'] = True\n",
    "\n",
    "# Add days between first interaction and booking\n",
    "df_client_journey_book['dif_days'] =   (df_client_journey_book['booking_time'] - df_client_journey['time']).dt.days\n",
    "\n",
    "\n",
    "df_client_journey['book'] = df_client_journey_book['book'] \n",
    "\n",
    "df_client_journey['dif_days'] = df_client_journey_book['dif_days'] \n",
    "\n",
    "\n",
    "df_client_journey[\"book\"].fillna( False, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add destination description\n",
    "\n",
    "dic_destCodes = {v: k for k, v in dic_destinations.items()}\n",
    "\n",
    "df_client_journey['destination_code'] = df_client_journey['destination_code'].map(dic_destCodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_client_journey.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save csv for Analitics\n",
    "\n",
    "df_client_journey.to_csv('data/data_analitic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following imnage show screenshot of  Qlik View using data/data_analitic.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"images/report.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/usr/bin/python3",
    "-m",
    "ipykernel",
    "--HistoryManager.enabled=False",
    "--matplotlib=inline",
    "-c",
    "%config InlineBackend.figure_formats = set(['retina'])\nimport matplotlib; matplotlib.rcParams['figure.figsize'] = (12, 7)",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (ipykernel)",
   "env": {},
   "language": "python",
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
